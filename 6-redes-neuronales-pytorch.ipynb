{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DjYDWVa3V4Tu"
      },
      "source": [
        "# **Módulo 3: Introducción a PyTorch**\n",
        "\n",
        "## Introducción\n",
        "[Pytorch](https://pytorch.org/) es una librería de tensores especializados para *deep learning* que utiliza CPU y GPU. Los tensores son estructuras de datos especializadas, muy similares a los *arrays* y las matrices. Se parecen a los *arrays* de NumPy, salvo porque los tensores se pueden ejecutar en una GPU u otros aceleradores de *hardware*. En el entrenamiento de modelos, las GPU ofrecen una capacidad de computación mucho más rápida y eficiente que la de las CPU. Además, los tensores incluyen una serie de cálculos de gradiente integrados que simplican el código en gran medida. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fm9PcH9l7OF"
      },
      "source": [
        "## Tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S982Co0hU4KB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKoQrkIRibH7"
      },
      "source": [
        "Estos son tensores creados directamente a partir de una lista. El tipo de datos se deduce automáticamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JoFxDrziLft",
        "outputId": "58420b2e-5f20-495c-97c8-40faa9628d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "tensor_data = torch.tensor(data)\n",
        "print(tensor_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-fcEJo8ijwq"
      },
      "source": [
        "# Este es un tensor creado a partir de un *array* de NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RAmdH0eirEH",
        "outputId": "b81ce15d-cce9-4b5d-88bf-bab48d22123e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "np_array = np.array(data)\n",
        "tensor_np = torch.from_numpy(np_array)\n",
        "print(tensor_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQaEudgTjVmu"
      },
      "source": [
        "Se pueden crear nuevos tensores a partir de otros. El nuevo tensor retiene las propiedades (forma, tipo de datos) del tensor argumento, a menos que se especifique lo contrario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bv283h9jYM7",
        "outputId": "bc8f528c-3897-4bf7-a07a-a62fe2eb586b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zeros Tensor: \n",
            " tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.3097, 0.9700, 0.5764],\n",
            "        [0.2597, 0.0588, 0.6836],\n",
            "        [0.2000, 0.3109, 0.4028]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_zeros = torch.zeros_like(tensor_data) # Retener las propiedades de tensor_data\n",
        "print(f\"Zeros Tensor: \\n {x_zeros} \\n\")\n",
        "\n",
        "x_ones = torch.ones_like(tensor_data) # Retener las propiedades de tensor_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(tensor_data, dtype=torch.float) # Anular los tipos de datos de tensor_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "853MH6qKkxLq"
      },
      "source": [
        "También se puede crear un tensor a partir de valores aleatorios o constantes.\n",
        "En la función que aparece más abajo, añadimos una tupla, la forma, que especifica la dimensión del tensor de *output*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sz-BFYyj2Ud",
        "outputId": "57671664-88c6-4cbd-db1d-0a185d05b540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zeros Tensor: \n",
            " tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "Ones Tensor: \n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.6332, 0.7867],\n",
            "        [0.4947, 0.7626],\n",
            "        [0.5672, 0.3837]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "shape = (3, 2,)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "rand_tensor = torch.rand(shape)\n",
        "\n",
        "\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XI0wuEkemCDF"
      },
      "source": [
        "Ademas de los conceptos de *forma* y *tipo de datos*; vamos a introducir un concepto nuevo, conocido como **dispositivo**, que especifica dónde se ejecutan los cálculos (hardware). Las GPU tienen un número mayor de unidades aritméticas lógicas o ALU, unidades de control y memoria caché cuya función básica es procesar en paralelo series de cálculos simples e idénticos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4J_bftel_9O",
        "outputId": "8ba2c346-3cd2-4013-afe7-08e1325f58fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of tensor: torch.Size([3, 2])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of tensor: {rand_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {rand_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {rand_tensor.device}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JG664MUWnX6e"
      },
      "source": [
        "Nvidia creó CUDA, una plataforma y arquitectura de computación en paralelo para sus GPU. El código que aparece más abajo cambiará el dispositivo de la CPU a la GPU, si hay una disponible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVKzN3GIjMdL",
        "outputId": "d6d2d080-3393-46a3-c1ce-96e4a601e24e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device tensor is stored on: cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  tensor = rand_tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JdJLa7OmH09"
      },
      "source": [
        "## Gradientes\n",
        "\n",
        "El siguiente ejemplo está extraído de: https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
        "\n",
        "El algoritmo más utilizado para entrenar redes neuronales es la retropropagación. En este algoritmo, se ajustan los parámetros (pesos del modelo) en función del gradiente de la función de pérdida respecto al parámetro dado.\n",
        "\n",
        "Para computar estos gradientes, PyTorch cuenta con un motor de diferenciación integrado llamado \"torch.autograd\", que soporta la computación automática del gradiente de cualquier gráfico computacional.\n",
        "\n",
        "Consideremos la red neuronal más sencilla de una capa, con un *input* x, parámetros w y b, y una función de pérdida. Se puede definir en PyTorch de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWhRW_LBtin5",
        "outputId": "5b127522-c706-465c-8a69-203213b3ee24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: tensor(1.4710, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5)  # Tensor de input\n",
        "y = torch.zeros(3)  # Output esperado\n",
        "# Shape of w: [5, 3]\n",
        "w = torch.randn(5, 3, requires_grad=True)   # Hay que computar el gradiente respecto a este parametro\n",
        "b = torch.randn(3, requires_grad=True)      # para optimizar la funcion de perdida\n",
        "z = torch.matmul(x, w)+b\n",
        "\n",
        "# Pérdida de Log-Verosimilitud Negativa (NLL)\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
        "\n",
        "print(\"loss:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F79eOVbzwVmZ"
      },
      "source": [
        "Una función que aplicamos a los tensores para construir gráficos computacionales es de hecho un objeto de la clase Función. Este objeto sabe cómo computar la función hacia delante, y también cómo computar su derivada durante el paso de retropropagación. En la propiedad grad_fn de un tensor se almacena una referencia a la función de retropropagación. Puede encontrar más información al respecto en la documentación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YFcXNXowQY-",
        "outputId": "0dc0a17c-e61a-40cf-c19c-69e9e2ea2da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7f69a57e8a60>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f699ced7580>\n"
          ]
        }
      ],
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b_XyUptwZmJ"
      },
      "source": [
        "Para optimizar los pesos de los parámetros de la red neuronal, tenemos que computar las derivadas de la función de pérdida respecto a los parámetros; concretamente, necesitamos $\\frac{\\partial loss}{\\partial w}$\n",
        "  y $\\frac{\\partial loss}{\\partial b}$ \n",
        "  con unos valores fijos de x e y. Para computar esas derivadas, llamamos a loss.backward(), y después recuperamos los valores de w.grad y b.grad:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRTeQITrwbgk",
        "outputId": "e13584e1-ab8d-4801-c475-af97765de879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3163, 0.0084, 0.2742],\n",
            "        [0.3163, 0.0084, 0.2742],\n",
            "        [0.3163, 0.0084, 0.2742],\n",
            "        [0.3163, 0.0084, 0.2742],\n",
            "        [0.3163, 0.0084, 0.2742]])\n",
            "tensor([0.3163, 0.0084, 0.2742])\n"
          ]
        }
      ],
      "source": [
        "loss.backward() # Calcular los gradientes\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpW79qRkmeK3"
      },
      "source": [
        "## Optimización\n",
        "\n",
        "Al utilizar las funciones de autodiferenciación de PyTorch, podemos realizar fácilmente las tareas de optimización necesarias para entrenar grandes redes neuronales. El fragmento de código que aparece más abajo nos permite trazar una función y su derivada correspondiente para visualizarlas.\n",
        "\n",
        "En *deep learning*, nuestro objetivo es minimizar la función de pérdida y, en este sencillo gráfico, vemos cómo la derivada nos puede informar del valor mínimo de una función dada.\n",
        "\n",
        "Fijémonos en el uso de .detach.numpy() para recuperar un valor del tensor y del dispositivo e introducirlo en un *array* de NumPy que lo trace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "nu0uilzUy3nM",
        "outputId": "03e6bffb-5e75-4c6b-e7ef-3ea7abe03120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(616., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Computar la derivada de la función con múltiples valores\n",
        "x = torch.linspace(-4, 4, 21, requires_grad = True)\n",
        "Y = 5*x ** 2\n",
        "y = torch.sum(Y)\n",
        "print(y)\n",
        "# y.backward()\n",
        " \n",
        "# Trazar la función y la derivada\n",
        "# ! detach: remover los grafos computacionales del tensor para pasarlo a numpy\n",
        "# plt.plot(x.detach().numpy(), Y.detach().numpy(), label = 'Function', color='r')\n",
        "# plt.plot(x.detach().numpy(), x.grad.detach().numpy(), label = 'Derivative', color='g')\n",
        "\n",
        "# plt.xlabel('x')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doTU0oTMLQhp"
      },
      "source": [
        "## ¿Qué viene después?\n",
        "\n",
        "Como hemos visto, los tensores pueden ser una herramienta muy potente y simplificar en gran medida la implementación de los programas. En los siguientes módulos, seguiremos construyendo sobre este marco de autogradiente y lo aplicaremos a redes neuronales más complejas. Para obtener más información sobre los tensores y sobre PyTorch, consulte el tutorial y los documentos que encontrará [aquí](https://pytorch.org/tutorials/beginner/basics/intro.html)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "1b4dcc508076e9239aa6a2b739d41c8a505780e648b690f375f7d262ba9ac310"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
